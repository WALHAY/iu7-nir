\ssr{ЗАКЛЮЧЕНИЕ}

Проблема обнаружения некорректных заимствований требует применения интегрированного подхода, сочетающего методы из различных классов:

\begin{itemize}

\item высокоскоростные методы обнаружения (отпечатки, LSH, шинглы) для быстрого отсеивания явно неподозрительных документов;

\item статистические и лексико-семантические методы (TF $\cdot$ IDF, опорные слова, расстояния, N-граммы) для детального сравнения;

\item современные нейросетевые методы (BERT, Siamese networks, LSTM) для выявления сложных парафраз и переводов;

\item стилометрический анализ для выявления внутридокументных разрывов стиля;

\item автоматизированные системы верификации источников и метаданных.

\end{itemize}

Экспериментальные исследования показывают, что ни один единственный метод не может быть универсален. Комбинация различных подходов, правильно настроенных и взвешенных в зависимости от контекста, обеспечивает высокую точность и полноту при обнаружении различных типов нарушений академической этики.

Наилучшие результаты по $F$-мере (0.82) показывает алгоритм Long Sent, основанный на выборе длинных предложений. Лексические методы обеспечивают высокую точность (до 0.97), но умеренную полноту. Методы на основе шинглов и мегашинглов эффективны для масштабных систем, но требуют тщательной настройки параметров. Дальнейшее развитие в этой области идет в направлении использования более мощных языковых моделей, лучшей интеграции методов верификации ссылок, разработки более эффективных алгоритмов кросс-языкового поиска плагиата, и создания специализированных систем для различных доменов и типов документов~\cite{zelenkov2007}.
